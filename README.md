Dataset:- https://drive.google.com/file/d/1aoPOthnz2MjjGWDWdrwyVkT8TVtPg0si/view?usp=sharing

Dashboard Visualizations:- https://drive.google.com/drive/folders/1NReTLnt5K_LQKdzjXXnsoz3dHwyQRzvc?usp=drive_link
# Aadhaar Infrastructure Decision Dashboard

A comprehensive data-driven decision support system for analyzing Aadhaar enrollment and update infrastructure stress across India. This project transforms raw Aadhaar transaction data into actionable insights for government infrastructure planning and resource allocation.

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Project Structure](#project-structure)
- [Data Pipeline](#data-pipeline)
- [Installation](#installation)
- [Usage](#usage)
- [Dashboard Components](#dashboard-components)
- [Data Quality](#data-quality)
- [Methodology](#methodology)
- [Contributing](#contributing)

## ğŸ¯ Overview

The Aadhaar Infrastructure Decision Dashboard is a government-focused analytical platform that:

- **Processes** millions of Aadhaar transaction records across India
- **Analyzes** enrollment and update patterns to identify infrastructure stress
- **Recommends** specific interventions (mobile vans, permanent centers, additional counters)
- **Quantifies** resource requirements (operators, budget, equipment)
- **Visualizes** insights through interactive maps, charts, and executive reports

Built with **no proprietary APIs** (uses OpenStreetMap), making it suitable for government deployment with minimal external dependencies.

## âœ¨ Features

### ğŸ“Š Analytics Engine
- **Stress Classification**: Categorizes districts into Critical/Warning/Normal based on EUR (Enrolment-Update Ratio)
- **Time-Window Analysis**: Evaluates patterns across short-term, mid-term, and long-term periods
- **Capacity Gap Estimation**: Calculates operator requirements and budget needs

### ğŸ—ºï¸ Interactive Dashboard
- **Stress Heatmap**: Geographic visualization of infrastructure stress using OpenStreetMap
- **Trend Analysis**: Time-series charts showing stress evolution
- **Decision Matrix**: Scatter plots correlating stress intensity with volatility
- **Recommendation Engine**: Rule-based system with full auditability
- **Action Tables**: Executive-ready CSV exports for administrative use
- **Rankings**: Top stressed and best-served districts for budget allocation
- **Capacity Planning**: Detailed staffing and budget projections

### ğŸ¨ Design Principles
- **Government-appropriate**: Professional styling, minimal external dependencies
- **Decision-driven**: Focuses on actionable outputs, not just analytics
- **Auditable**: Rule-based recommendations (no black-box ML)
- **Exportable**: All insights available as downloadable CSV files

## ğŸ“ Project Structure

```
UIDAI-Hack/
â”œâ”€â”€ dashboard/
â”‚   â”œâ”€â”€ app.py                          # Main Streamlit application
â”‚   â”œâ”€â”€ data_loader.py                  # Data loading and preprocessing
â”‚   â””â”€â”€ components/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ heatmap.py                  # Geographic stress visualization
â”‚       â”œâ”€â”€ time_series.py              # Trend analysis charts
â”‚       â”œâ”€â”€ scatter.py                  # Decision matrix visualization
â”‚       â”œâ”€â”€ recommendation_engine.py    # Rule-based intervention logic
â”‚       â”œâ”€â”€ action_table.py             # Executive action plan tables
â”‚       â”œâ”€â”€ rankings.py                 # Priority rankings
â”‚       â””â”€â”€ capacity_gap.py             # Resource requirement estimation
â”‚
â”œâ”€â”€ data_preprocessing.py               # Initial data merging script
â”œâ”€â”€ clean_master_data.py                # State/district standardization
â”œâ”€â”€ aggregate_duplicates_v2.py          # Duplicate consolidation
â”œâ”€â”€ 03_eur_stability_and_intervention_classification.ipynb  # Analysis notebook
â”œâ”€â”€ data_quality_check.ipynb            # Quality validation notebook
â”‚
â”œâ”€â”€ district_recommendations.csv        # Primary analysis output
â”œâ”€â”€ operator_requirements.csv           # Capacity requirements
â”œâ”€â”€ aadhaar_daily_activity.csv         # Daily transaction aggregates
â”œâ”€â”€ final_aadhaar_intervention_classification.csv  # Complete classification
â”‚
â”œâ”€â”€ requirements.txt                    # Python dependencies
â””â”€â”€ README.md                          # This file
```

## ğŸ”„ Data Pipeline

### 1. **Data Collection** (Raw Data)
- **Source Files**: Separate CSVs for Enrolments, Biometric Updates, Demographic Updates
- **Coverage**: 36 states/UTs, 1000+ districts, 19,000+ pincodes
- **Time Range**: March 2025 - December 2025 (115 days)

### 2. **Preprocessing** (`data_preprocessing.py`)
```python
# Merges three data streams
python data_preprocessing.py
```
**Output**: `master_aadhaar_data.csv`

**Processes**:
- Loads enrolment, biometric, and demographic data
- Performs outer joins on [date, state, district, pincode]
- Calculates derived metrics:
  - `total_enrolments` = age_0_5 + age_5_17 + age_18_greater
  - `total_updates` = biometric + demographic updates
  - `update_to_enrolment_ratio`
  - `overall_activity` = enrolments + updates
- Adds temporal features (month_name, day_name, is_weekend)

### 3. **Data Cleaning** (`clean_master_data.py`)
```python
python clean_master_data.py
```
**Output**: `master_aadhaar_data_final_cleaned.csv`

**Standardizations**:
- **State Names**: 
  - Case normalization ("andhra Pradesh" â†’ "Andhra Pradesh")
  - Spelling fixes ("Chhatisgarh" â†’ "Chhattisgarh")
  - UT consolidations ("Daman & Diu" â†’ "Dadra and Nagar Haveli and Daman and Diu")
- **District Names**: Title case standardization
- **Data Types**: Ensures integers for counts, handles missing values
- **Invalid Records**: Removes '100000' placeholder entries

### 4. **Duplicate Aggregation** (`aggregate_duplicates_v2.py`)
```python
python aggregate_duplicates_v2.py
```
**Output**: `master_aadhaar_data_fully_cleaned.csv`

**Process**:
- Groups by [date, state, district, pincode]
- Sums all transaction counts
- Recalculates derived ratios
- Ensures unique keys

### 5. **EUR Analysis & Classification** (Jupyter Notebook)
```python
# Run in Jupyter/Google Colab
03_eur_stability_and_intervention_classification.ipynb
```
**Outputs**: 
- `district_recommendations.csv`
- `operator_requirements.csv`
- `final_aadhaar_intervention_classification.csv`

**Analysis**:
1. **EUR Calculation**: 
   ```
   EUR = total_updates / (total_enrolments + 0.1)
   ```
2. **Statistical Features**:
   - `eur_mean`: Average stress intensity
   - `eur_std`: Volatility measure
   - `stress_percentile`: Relative ranking (0-100)

3. **Window Classification**:
   - Short-term: < 30 days of data
   - Mid-term: 30-90 days
   - Long-term: > 90 days

4. **Intervention Logic**:
   ```
   IF stress_percentile > 85% AND window = short_term:
       recommendation = "Mobile Aadhaar Van"
   ELIF stress_percentile > 85% AND window IN [mid_term, long_term]:
       recommendation = "Permanent Centre"
   ELIF stress_percentile > 50%:
       recommendation = "Extra Counters"
   ELSE:
       recommendation = "Monitor / No Action"
   ```

5. **Capacity Estimation**:
   ```
   operators_needed = daily_gap / operator_capacity
   daily_gap = max(0, avg_daily_activity - current_capacity)
   ```

### 6. **Quality Validation** (`data_quality_check.ipynb`)

Comprehensive checks for:
- âœ… Null values (0 found)
- âœ… Duplicates (0 after aggregation)
- âœ… State name consistency (36 unique states)
- âœ… District-state mappings
- âœ… Pincode validity (6-digit format)
- âœ… Data type correctness
- âœ… Temporal coverage

## ğŸš€ Installation

### Prerequisites
- Python 3.8+
- pip package manager

### Setup

1. **Clone the repository**
   ```bash
   git clone https://github.com/ANISHTWAGLE/UIDAI-Hack.git
   cd UIDAI-Hack
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Download the dataset**
   - Download from [Google Drive](https://drive.google.com/file/d/1aoPOthnz2MjjGWDWdrwyVkT8TVtPg0si/view?usp=sharing)
   - Extract to project root directory

## ğŸ“– Usage

### Running the Dashboard

```bash
streamlit run dashboard/app.py
```

The dashboard will open in your browser at `http://localhost:8501`

### Running the Data Pipeline

**Complete Pipeline**:
```bash
# Step 1: Merge raw data
python data_preprocessing.py

# Step 2: Clean and standardize
python clean_master_data.py

# Step 3: Aggregate duplicates
python aggregate_duplicates_v2.py

# Step 4: Run EUR analysis (in Jupyter)
jupyter notebook 03_eur_stability_and_intervention_classification.ipynb

# Step 5: Launch dashboard
streamlit run dashboard/app.py
```

## ğŸ›ï¸ Dashboard Components

### 1. ğŸ—ºï¸ Stress Map
- **OpenStreetMap Integration**: No API keys required
- **Heat Layer**: Red clusters indicate critical stress
- **District Markers**: Click for detailed recommendations
- **Legend**: Color-coded by intervention type

### 2. ğŸ“ˆ Trends
- **Window Class Analysis**: Short/mid/long-term patterns
- **Enrolments vs Updates**: State-level comparisons
- **Stress Distribution**: Histogram with thresholds at 50% and 85%

### 3. ğŸ¯ Decisions
- **Decision Matrix**: EUR Mean (intensity) vs EUR Std (volatility)
- **Quadrant Logic**: 
  - High stress + High volatility â†’ Mobile Van
  - High stress + Low volatility â†’ Permanent Centre
  - Medium stress â†’ Extra Counters
  - Low stress â†’ Monitor

### 4. ğŸ§  Engine
- **Rule Display**: Complete decision logic for auditability
- **Distribution Pie Chart**: Recommendations by type
- **District Lookup**: Search specific locations
- **Audit Summary**: Aggregated statistics

### 5. ğŸ“‹ Actions
- **Executive Table**: Sorted by stress severity
- **Filtering**: By state, action type, operator requirements
- **CSV Export**: Ready for administrative use
- **State Summary**: Aggregated view

### 6. ğŸ† Rankings
- **Top 10 Most Stressed**: Priority for intervention
- **Top 10 Best Served**: Potential for reallocation
- **State Overview**: Average stress by state
- **Detailed Tables**: Full district information

### 7. ğŸ§® Capacity
- **Configurable Assumptions**:
  - Operator capacity (default: 50 transactions/day)
  - Salary (default: â‚¹15,000/month)
  - Hardware cost (default: â‚¹3,00,000/station)
  - Monthly rent (default: â‚¹20,000/station)

- **Outputs**:
  - Total operators needed
  - Monthly recurring costs
  - One-time hardware budget
  - First-year total budget
  - State-wise breakdowns

### Sidebar Filters
- **State Selection**: All states or specific state
- **District Selection**: Depends on state filter
- **Stress Category**: Critical/Warning/Normal
- **Quick Stats**: Real-time counts

## âœ… Data Quality

### Final Dataset Statistics
- **Total Records**: 2,307,730
- **Null Values**: 0
- **Duplicates**: 0
- **States**: 36 (matches official count)
- **Districts**: 1,001
- **Pincodes**: 19,814
- **Date Range**: March 1, 2025 - December 31, 2025

### Known Data Characteristics
- **Multi-state Districts**: 23 districts appear in multiple states (e.g., Hyderabad in Andhra Pradesh and Telangana)
- **Multi-state Pincodes**: 705 pincodes span state borders (border regions)
- **Missing Months**: August 2025 has no data
- **Partial Months**: March-July 2025 have limited daily coverage

## ğŸ§ª Methodology

### Stress Metrics

**EUR (Enrolment-Update Ratio)**:
```
EUR = Total Updates / (Total Enrolments + 0.1)
```
- Higher EUR â†’ More update load relative to enrolments
- Indicates infrastructure strain

**Stress Percentile**:
- Ranks districts from 0-100%
- Uses empirical distribution
- Accounts for both mean and standard deviation

### Intervention Thresholds

| Stress Level | Percentile | Recommendation | Rationale |
|--------------|------------|----------------|-----------|
| Critical | >85% | Mobile Van / Permanent Centre | Immediate action required |
| Warning | 50-85% | Extra Counters / Temporary Support | Preventive measures |
| Normal | <50% | Monitor / No Action | Within acceptable range |

### Capacity Calculation

```python
daily_gap = max(0, avg_daily_activity - current_capacity)
operators_needed = ceiling(daily_gap / operator_capacity)
```

**Assumptions**:
- Operator capacity: 50 transactions/day (configurable)
- Working days: 25 days/month (configurable)

## ğŸ‘¥ Contributors

- [Anish Wagle](https://github.com/ANISHTWAGLE) - Project Lead
- [geeky33](https://github.com/geeky33)
- [Shreyas Gurav](https://github.com/shreyasgurav)

## ğŸ“„ License

This project is intended for government use and academic purposes. Please contact the maintainers for usage permissions.

## ğŸ™ Acknowledgments

- UIDAI for Aadhaar infrastructure data
- OpenStreetMap for mapping capabilities
- Streamlit for the dashboard framework
- Plotly for interactive visualizations

## ğŸ“ Support

For issues, questions, or contributions:
- Open an issue on GitHub
- Contact the maintainers directly

---

**Built for government deployment with minimal external dependencies** | **Decision-Driven Government Dashboard** | **Powered by OpenStreetMap**
