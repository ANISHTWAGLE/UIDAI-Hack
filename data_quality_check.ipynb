{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Data Quality Check - Master Aadhaar Data\n",
                "\n",
                "This notebook performs comprehensive data quality checks on the `master_aadhaar_data_final_cleaned.csv` file to identify:\n",
                "- Null values\n",
                "- Duplicate rows\n",
                "- State name mismatches/inconsistencies\n",
                "- District name mismatches/inconsistencies\n",
                "- Pincode issues\n",
                "- Data type validation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# For better display\n",
                "pd.set_option('display.max_columns', None)\n",
                "pd.set_option('display.max_rows', 100)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load the Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Dataset Shape: (2307730, 20)\n",
                        "Total Rows: 2,307,730\n",
                        "Total Columns: 20\n",
                        "\n",
                        "First few rows:\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>date</th>\n",
                            "      <th>state</th>\n",
                            "      <th>district</th>\n",
                            "      <th>pincode</th>\n",
                            "      <th>month_name</th>\n",
                            "      <th>day_name</th>\n",
                            "      <th>is_weekend</th>\n",
                            "      <th>age_0_5</th>\n",
                            "      <th>age_5_17</th>\n",
                            "      <th>age_18_greater</th>\n",
                            "      <th>bio_age_5_17</th>\n",
                            "      <th>bio_age_18_greater</th>\n",
                            "      <th>demo_age_5_17</th>\n",
                            "      <th>demo_age_18_greater</th>\n",
                            "      <th>total_enrolments</th>\n",
                            "      <th>total_biometric_updates</th>\n",
                            "      <th>total_demographic_updates</th>\n",
                            "      <th>total_updates</th>\n",
                            "      <th>overall_activity</th>\n",
                            "      <th>update_to_enrolment_ratio</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>2025-03-01</td>\n",
                            "      <td>Andaman and Nicobar Islands</td>\n",
                            "      <td>Andamans</td>\n",
                            "      <td>744101</td>\n",
                            "      <td>March</td>\n",
                            "      <td>Saturday</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>16</td>\n",
                            "      <td>193</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>209</td>\n",
                            "      <td>0</td>\n",
                            "      <td>209</td>\n",
                            "      <td>209</td>\n",
                            "      <td>2090.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>2025-03-01</td>\n",
                            "      <td>Andaman and Nicobar Islands</td>\n",
                            "      <td>Nicobar</td>\n",
                            "      <td>744301</td>\n",
                            "      <td>March</td>\n",
                            "      <td>Saturday</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>101</td>\n",
                            "      <td>48</td>\n",
                            "      <td>16</td>\n",
                            "      <td>180</td>\n",
                            "      <td>0</td>\n",
                            "      <td>149</td>\n",
                            "      <td>196</td>\n",
                            "      <td>345</td>\n",
                            "      <td>345</td>\n",
                            "      <td>3450.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>2025-03-01</td>\n",
                            "      <td>Andaman and Nicobar Islands</td>\n",
                            "      <td>Nicobar</td>\n",
                            "      <td>744302</td>\n",
                            "      <td>March</td>\n",
                            "      <td>Saturday</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>15</td>\n",
                            "      <td>12</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>27</td>\n",
                            "      <td>0</td>\n",
                            "      <td>27</td>\n",
                            "      <td>27</td>\n",
                            "      <td>270.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>2025-03-01</td>\n",
                            "      <td>Andaman and Nicobar Islands</td>\n",
                            "      <td>Nicobar</td>\n",
                            "      <td>744303</td>\n",
                            "      <td>March</td>\n",
                            "      <td>Saturday</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>46</td>\n",
                            "      <td>27</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>73</td>\n",
                            "      <td>0</td>\n",
                            "      <td>73</td>\n",
                            "      <td>73</td>\n",
                            "      <td>730.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>2025-03-01</td>\n",
                            "      <td>Andaman and Nicobar Islands</td>\n",
                            "      <td>Nicobar</td>\n",
                            "      <td>744304</td>\n",
                            "      <td>March</td>\n",
                            "      <td>Saturday</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>16</td>\n",
                            "      <td>14</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>30</td>\n",
                            "      <td>0</td>\n",
                            "      <td>30</td>\n",
                            "      <td>30</td>\n",
                            "      <td>300.0</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "         date                        state  district  pincode month_name  \\\n",
                            "0  2025-03-01  Andaman and Nicobar Islands  Andamans   744101      March   \n",
                            "1  2025-03-01  Andaman and Nicobar Islands   Nicobar   744301      March   \n",
                            "2  2025-03-01  Andaman and Nicobar Islands   Nicobar   744302      March   \n",
                            "3  2025-03-01  Andaman and Nicobar Islands   Nicobar   744303      March   \n",
                            "4  2025-03-01  Andaman and Nicobar Islands   Nicobar   744304      March   \n",
                            "\n",
                            "   day_name  is_weekend  age_0_5  age_5_17  age_18_greater  bio_age_5_17  \\\n",
                            "0  Saturday           1        0         0               0            16   \n",
                            "1  Saturday           1        0         0               0           101   \n",
                            "2  Saturday           1        0         0               0            15   \n",
                            "3  Saturday           1        0         0               0            46   \n",
                            "4  Saturday           1        0         0               0            16   \n",
                            "\n",
                            "   bio_age_18_greater  demo_age_5_17  demo_age_18_greater  total_enrolments  \\\n",
                            "0                 193              0                    0                 0   \n",
                            "1                  48             16                  180                 0   \n",
                            "2                  12              0                    0                 0   \n",
                            "3                  27              0                    0                 0   \n",
                            "4                  14              0                    0                 0   \n",
                            "\n",
                            "   total_biometric_updates  total_demographic_updates  total_updates  \\\n",
                            "0                      209                          0            209   \n",
                            "1                      149                        196            345   \n",
                            "2                       27                          0             27   \n",
                            "3                       73                          0             73   \n",
                            "4                       30                          0             30   \n",
                            "\n",
                            "   overall_activity  update_to_enrolment_ratio  \n",
                            "0               209                     2090.0  \n",
                            "1               345                     3450.0  \n",
                            "2                27                      270.0  \n",
                            "3                73                      730.0  \n",
                            "4                30                      300.0  "
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Load the dataset\n",
                "df = pd.read_csv('master_aadhaar_data_fully_cleaned.csv')\n",
                "\n",
                "print(f\"Dataset Shape: {df.shape}\")\n",
                "print(f\"Total Rows: {df.shape[0]:,}\")\n",
                "print(f\"Total Columns: {df.shape[1]}\")\n",
                "print(\"\\nFirst few rows:\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Basic Dataset Information"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Dataset Information:\n",
                        "================================================================================\n",
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 2330372 entries, 0 to 2330371\n",
                        "Data columns (total 20 columns):\n",
                        " #   Column                     Dtype  \n",
                        "---  ------                     -----  \n",
                        " 0   date                       object \n",
                        " 1   state                      object \n",
                        " 2   district                   object \n",
                        " 3   pincode                    int64  \n",
                        " 4   age_0_5                    int64  \n",
                        " 5   age_5_17                   int64  \n",
                        " 6   age_18_greater             int64  \n",
                        " 7   bio_age_5_17               int64  \n",
                        " 8   bio_age_18_greater         int64  \n",
                        " 9   demo_age_5_17              int64  \n",
                        " 10  demo_age_18_greater        int64  \n",
                        " 11  total_enrolments           int64  \n",
                        " 12  total_biometric_updates    int64  \n",
                        " 13  total_demographic_updates  int64  \n",
                        " 14  total_updates              int64  \n",
                        " 15  overall_activity           int64  \n",
                        " 16  update_to_enrolment_ratio  float64\n",
                        " 17  month_name                 object \n",
                        " 18  day_name                   object \n",
                        " 19  is_weekend                 int64  \n",
                        "dtypes: float64(1), int64(14), object(5)\n",
                        "memory usage: 355.6+ MB\n"
                    ]
                }
            ],
            "source": [
                "# Dataset info\n",
                "print(\"Dataset Information:\")\n",
                "print(\"=\"*80)\n",
                "df.info()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Column Names:\n",
                        "================================================================================\n",
                        " 1. date\n",
                        " 2. state\n",
                        " 3. district\n",
                        " 4. pincode\n",
                        " 5. age_0_5\n",
                        " 6. age_5_17\n",
                        " 7. age_18_greater\n",
                        " 8. bio_age_5_17\n",
                        " 9. bio_age_18_greater\n",
                        "10. demo_age_5_17\n",
                        "11. demo_age_18_greater\n",
                        "12. total_enrolments\n",
                        "13. total_biometric_updates\n",
                        "14. total_demographic_updates\n",
                        "15. total_updates\n",
                        "16. overall_activity\n",
                        "17. update_to_enrolment_ratio\n",
                        "18. month_name\n",
                        "19. day_name\n",
                        "20. is_weekend\n"
                    ]
                }
            ],
            "source": [
                "# Column names\n",
                "print(\"\\nColumn Names:\")\n",
                "print(\"=\"*80)\n",
                "for i, col in enumerate(df.columns, 1):\n",
                "    print(f\"{i:2}. {col}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Check for Null Values"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "================================================================================\n",
                        "NULL VALUE ANALYSIS\n",
                        "================================================================================\n",
                        "\n",
                        "✓ No null values found in the dataset!\n",
                        "\n",
                        "Total Null Values: 0\n"
                    ]
                }
            ],
            "source": [
                "# Check null values\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"NULL VALUE ANALYSIS\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "null_counts = df.isnull().sum()\n",
                "null_percentages = (df.isnull().sum() / len(df)) * 100\n",
                "\n",
                "null_df = pd.DataFrame({\n",
                "    'Column': null_counts.index,\n",
                "    'Null Count': null_counts.values,\n",
                "    'Null Percentage': null_percentages.values\n",
                "})\n",
                "\n",
                "null_df = null_df[null_df['Null Count'] > 0].sort_values('Null Count', ascending=False)\n",
                "\n",
                "if len(null_df) > 0:\n",
                "    print(\"\\n⚠️ COLUMNS WITH NULL VALUES:\")\n",
                "    print(null_df.to_string(index=False))\n",
                "else:\n",
                "    print(\"\\n✓ No null values found in the dataset!\")\n",
                "\n",
                "# Total nulls\n",
                "total_nulls = df.isnull().sum().sum()\n",
                "print(f\"\\nTotal Null Values: {total_nulls:,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Check for Duplicate Rows"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "================================================================================\n",
                        "DUPLICATE ROWS ANALYSIS\n",
                        "================================================================================\n",
                        "\n",
                        "Total Duplicate Rows (exact duplicates): 0\n",
                        "✓ No exact duplicate rows found!\n",
                        "\n",
                        "Duplicate rows based on key columns ['date', 'state', 'district', 'pincode']: 0\n",
                        "✓ No duplicate key combinations found!\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"DUPLICATE ROWS ANALYSIS\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "# Check for complete duplicates\n",
                "duplicate_rows = df.duplicated().sum()\n",
                "print(f\"\\nTotal Duplicate Rows (exact duplicates): {duplicate_rows:,}\")\n",
                "\n",
                "if duplicate_rows > 0:\n",
                "    print(f\"Percentage of duplicates: {(duplicate_rows/len(df)*100):.2f}%\")\n",
                "    print(\"\\n⚠️ Sample of duplicate rows:\")\n",
                "    display(df[df.duplicated(keep=False)].head(10))\n",
                "else:\n",
                "    print(\"✓ No exact duplicate rows found!\")\n",
                "\n",
                "# Check for duplicates based on key columns (date, state, district, pincode)\n",
                "key_columns = ['date', 'state', 'district', 'pincode']\n",
                "duplicate_keys = df.duplicated(subset=key_columns).sum()\n",
                "print(f\"\\nDuplicate rows based on key columns {key_columns}: {duplicate_keys:,}\")\n",
                "\n",
                "if duplicate_keys > 0:\n",
                "    print(f\"Percentage of key duplicates: {(duplicate_keys/len(df)*100):.2f}%\")\n",
                "    print(\"\\n⚠️ Sample of duplicate key combinations:\")\n",
                "    display(df[df.duplicated(subset=key_columns, keep=False)].sort_values(key_columns).head(10))\n",
                "else:\n",
                "    print(\"✓ No duplicate key combinations found!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. State Names Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "================================================================================\n",
                        "STATE NAMES ANALYSIS\n",
                        "================================================================================\n",
                        "\n",
                        "Total Unique States: 36\n",
                        "Expected States/UTs in India: ~36\n",
                        "\n",
                        "All Unique State Names:\n",
                        "  1. Andaman and Nicobar Islands                        (Records: 1,975)\n",
                        "  2. Andhra Pradesh                                     (Records: 220,344)\n",
                        "  3. Arunachal Pradesh                                  (Records: 5,351)\n",
                        "  4. Assam                                              (Records: 64,630)\n",
                        "  5. Bihar                                              (Records: 104,072)\n",
                        "  6. Chandigarh                                         (Records: 2,118)\n",
                        "  7. Chhattisgarh                                       (Records: 38,863)\n",
                        "  8. Dadra and Nagar Haveli and Daman and Diu           (Records: 1,043)\n",
                        "  9. Delhi                                              (Records: 11,295)\n",
                        " 10. Goa                                                (Records: 6,841)\n",
                        " 11. Gujarat                                            (Records: 110,943)\n",
                        " 12. Haryana                                            (Records: 31,494)\n",
                        " 13. Himachal Pradesh                                   (Records: 36,340)\n",
                        " 14. Jammu and Kashmir                                  (Records: 23,271)\n",
                        " 15. Jharkhand                                          (Records: 44,573)\n",
                        " 16. Karnataka                                          (Records: 178,483)\n",
                        " 17. Kerala                                             (Records: 119,941)\n",
                        " 18. Ladakh                                             (Records: 975)\n",
                        " 19. Lakshadweep                                        (Records: 692)\n",
                        " 20. Madhya Pradesh                                     (Records: 86,008)\n",
                        " 21. Maharashtra                                        (Records: 181,764)\n",
                        " 22. Manipur                                            (Records: 8,268)\n",
                        " 23. Meghalaya                                          (Records: 6,448)\n",
                        " 24. Mizoram                                            (Records: 4,599)\n",
                        " 25. Nagaland                                           (Records: 5,031)\n",
                        " 26. Odisha                                             (Records: 107,833)\n",
                        " 27. Puducherry                                         (Records: 5,169)\n",
                        " 28. Punjab                                             (Records: 57,820)\n",
                        " 29. Rajasthan                                          (Records: 101,204)\n",
                        " 30. Sikkim                                             (Records: 3,586)\n",
                        " 31. Tamil Nadu                                         (Records: 228,934)\n",
                        " 32. Telangana                                          (Records: 102,225)\n",
                        " 33. Tripura                                            (Records: 10,086)\n",
                        " 34. Uttar Pradesh                                      (Records: 190,896)\n",
                        " 35. Uttarakhand                                        (Records: 26,920)\n",
                        " 36. West Bengal                                        (Records: 177,695)\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"STATE NAMES ANALYSIS\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "# Get unique states\n",
                "unique_states = df['state'].unique()\n",
                "print(f\"\\nTotal Unique States: {len(unique_states)}\")\n",
                "print(f\"Expected States/UTs in India: ~36\")\n",
                "\n",
                "# Display all unique states\n",
                "print(\"\\nAll Unique State Names:\")\n",
                "for i, state in enumerate(sorted(unique_states), 1):\n",
                "    state_count = df[df['state'] == state].shape[0]\n",
                "    print(f\"{i:3}. {state:<50} (Records: {state_count:,})\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "================================================================================\n",
                        "POTENTIAL STATE NAME ISSUES\n",
                        "================================================================================\n",
                        "✓ No case/whitespace inconsistencies found in state names!\n"
                    ]
                }
            ],
            "source": [
                "# Check for potential state name issues\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"POTENTIAL STATE NAME ISSUES\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "# Normalize state names for comparison\n",
                "df['state_normalized'] = df['state'].str.strip().str.lower()\n",
                "\n",
                "# Check for case inconsistencies\n",
                "state_variations = df.groupby('state_normalized')['state'].unique()\n",
                "inconsistent_states = state_variations[state_variations.apply(len) > 1]\n",
                "\n",
                "if len(inconsistent_states) > 0:\n",
                "    print(\"\\n⚠️ State names with case/whitespace inconsistencies:\")\n",
                "    for normalized, variations in inconsistent_states.items():\n",
                "        print(f\"\\nNormalized: '{normalized}'\")\n",
                "        for var in variations:\n",
                "            count = df[df['state'] == var].shape[0]\n",
                "            print(f\"  - '{var}' (Records: {count:,})\")\n",
                "else:\n",
                "    print(\"✓ No case/whitespace inconsistencies found in state names!\")\n",
                "\n",
                "# Remove temporary column\n",
                "df.drop('state_normalized', axis=1, inplace=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "================================================================================\n",
                        "CHECKING FOR SIMILAR STATE NAMES (POTENTIAL TYPOS)\n",
                        "================================================================================\n",
                        "\n",
                        "⚠️ Potentially similar state names found:\n",
                        "\n",
                        "Similarity: 85.71%\n",
                        "  1. 'Andhra Pradesh' (Records: 220,394)\n",
                        "  2. 'Madhya Pradesh' (Records: 86,008)\n",
                        "\n",
                        "Similarity: 80.00%\n",
                        "  1. 'Himachal Pradesh' (Records: 36,340)\n",
                        "  2. 'Madhya Pradesh' (Records: 86,008)\n",
                        "\n",
                        "Similarity: 78.79%\n",
                        "  1. 'Arunachal Pradesh' (Records: 5,351)\n",
                        "  2. 'Himachal Pradesh' (Records: 36,340)\n",
                        "\n",
                        "Similarity: 77.42%\n",
                        "  1. 'Andhra Pradesh' (Records: 220,394)\n",
                        "  2. 'Arunachal Pradesh' (Records: 5,351)\n",
                        "\n",
                        "Similarity: 74.07%\n",
                        "  1. 'Andhra Pradesh' (Records: 220,394)\n",
                        "  2. 'Uttar Pradesh' (Records: 190,896)\n",
                        "\n",
                        "Similarity: 73.33%\n",
                        "  1. 'Andhra Pradesh' (Records: 220,394)\n",
                        "  2. 'Himachal Pradesh' (Records: 36,340)\n",
                        "\n",
                        "Similarity: 72.73%\n",
                        "  1. 'Chandigarh' (Records: 2,118)\n",
                        "  2. 'Chhattisgarh' (Records: 38,870)\n",
                        "\n",
                        "Similarity: 70.00%\n",
                        "  1. 'Jharkhand' (Records: 45,629)\n",
                        "  2. 'Uttarakhand' (Records: 26,922)\n",
                        "\n",
                        "Similarity: 66.67%\n",
                        "  1. 'Arunachal Pradesh' (Records: 5,351)\n",
                        "  2. 'Uttar Pradesh' (Records: 190,896)\n",
                        "\n",
                        "Similarity: 66.67%\n",
                        "  1. 'Madhya Pradesh' (Records: 86,008)\n",
                        "  2. 'Uttar Pradesh' (Records: 190,896)\n",
                        "\n",
                        "Similarity: 64.52%\n",
                        "  1. 'Arunachal Pradesh' (Records: 5,351)\n",
                        "  2. 'Madhya Pradesh' (Records: 86,008)\n",
                        "\n",
                        "Similarity: 64.00%\n",
                        "  1. 'Madhya Pradesh' (Records: 86,008)\n",
                        "  2. 'Maharashtra' (Records: 181,764)\n",
                        "\n",
                        "Similarity: 62.50%\n",
                        "  1. 'Haryana' (Records: 31,494)\n",
                        "  2. 'Jharkhand' (Records: 45,629)\n",
                        "\n",
                        "Similarity: 62.07%\n",
                        "  1. 'Himachal Pradesh' (Records: 36,340)\n",
                        "  2. 'Uttar Pradesh' (Records: 190,896)\n"
                    ]
                }
            ],
            "source": [
                "# Check for similar state names (potential typos)\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"CHECKING FOR SIMILAR STATE NAMES (POTENTIAL TYPOS)\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "from difflib import SequenceMatcher\n",
                "\n",
                "def similarity(a, b):\n",
                "    return SequenceMatcher(None, a.lower(), b.lower()).ratio()\n",
                "\n",
                "# Find similar state names\n",
                "similar_states = []\n",
                "states_list = sorted(unique_states)\n",
                "\n",
                "for i in range(len(states_list)):\n",
                "    for j in range(i+1, len(states_list)):\n",
                "        sim = similarity(states_list[i], states_list[j])\n",
                "        if 0.6 < sim < 1.0:  # Similar but not identical\n",
                "            similar_states.append((states_list[i], states_list[j], sim))\n",
                "\n",
                "if similar_states:\n",
                "    print(\"\\n⚠️ Potentially similar state names found:\")\n",
                "    for state1, state2, sim in sorted(similar_states, key=lambda x: x[2], reverse=True):\n",
                "        count1 = df[df['state'] == state1].shape[0]\n",
                "        count2 = df[df['state'] == state2].shape[0]\n",
                "        print(f\"\\nSimilarity: {sim:.2%}\")\n",
                "        print(f\"  1. '{state1}' (Records: {count1:,})\")\n",
                "        print(f\"  2. '{state2}' (Records: {count2:,})\")\n",
                "else:\n",
                "    print(\"\\n✓ No similar state names found!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. District Names Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "================================================================================\n",
                        "DISTRICT NAMES ANALYSIS\n",
                        "================================================================================\n",
                        "\n",
                        "Total Unique Districts: 1001\n",
                        "Expected Districts in India: ~750\n",
                        "\n",
                        "Districts per State (Top 10):\n",
                        "state\n",
                        "Uttar Pradesh     96\n",
                        "Madhya Pradesh    61\n",
                        "Karnataka         56\n",
                        "Maharashtra       55\n",
                        "West Bengal       55\n",
                        "Bihar             48\n",
                        "Andhra Pradesh    48\n",
                        "Tamil Nadu        47\n",
                        "Odisha            46\n",
                        "Rajasthan         46\n",
                        "Name: district, dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"DISTRICT NAMES ANALYSIS\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "# Get unique districts\n",
                "unique_districts = df['district'].unique()\n",
                "print(f\"\\nTotal Unique Districts: {len(unique_districts)}\")\n",
                "print(f\"Expected Districts in India: ~750\")\n",
                "\n",
                "# Districts per state\n",
                "districts_per_state = df.groupby('state')['district'].nunique().sort_values(ascending=False)\n",
                "print(\"\\nDistricts per State (Top 10):\")\n",
                "print(districts_per_state.head(10))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "================================================================================\n",
                        "DISTRICTS APPEARING IN MULTIPLE STATES\n",
                        "================================================================================\n",
                        "\n",
                        "⚠️ 23 districts found in multiple states:\n",
                        "\n",
                        "District: 'Adilabad'\n",
                        "  - Andhra Pradesh (Records: 3,813)\n",
                        "  - Telangana (Records: 4,164)\n",
                        "\n",
                        "District: 'Aurangabad'\n",
                        "  - Bihar (Records: 2,707)\n",
                        "  - Maharashtra (Records: 4,023)\n",
                        "\n",
                        "District: 'Balrampur'\n",
                        "  - Chhattisgarh (Records: 722)\n",
                        "  - Uttar Pradesh (Records: 1,415)\n",
                        "\n",
                        "District: 'Bijapur'\n",
                        "  - Chhattisgarh (Records: 582)\n",
                        "  - Karnataka (Records: 4,025)\n",
                        "\n",
                        "District: 'Bilaspur'\n",
                        "  - Chhattisgarh (Records: 2,330)\n",
                        "  - Himachal Pradesh (Records: 2,158)\n",
                        "\n",
                        "District: 'Cuddalore'\n",
                        "  - Tamil Nadu (Records: 6,431)\n",
                        "  - Puducherry (Records: 5)\n",
                        "\n",
                        "District: 'Hamirpur'\n",
                        "  - Himachal Pradesh (Records: 3,682)\n",
                        "  - Uttar Pradesh (Records: 1,417)\n",
                        "\n",
                        "District: 'Hyderabad'\n",
                        "  - Andhra Pradesh (Records: 5,219)\n",
                        "  - Telangana (Records: 5,973)\n",
                        "\n",
                        "District: 'K.V. Rangareddy'\n",
                        "  - Andhra Pradesh (Records: 358)\n",
                        "  - Telangana (Records: 8,687)\n",
                        "\n",
                        "District: 'Kamrup'\n",
                        "  - Assam (Records: 3,788)\n",
                        "  - Meghalaya (Records: 1)\n",
                        "\n",
                        "District: 'Kargil'\n",
                        "  - Jammu and Kashmir (Records: 579)\n",
                        "  - Ladakh (Records: 537)\n",
                        "\n",
                        "District: 'Karimnagar'\n",
                        "  - Andhra Pradesh (Records: 4,113)\n",
                        "  - Telangana (Records: 7,441)\n",
                        "\n",
                        "District: 'Khammam'\n",
                        "  - Andhra Pradesh (Records: 4,608)\n",
                        "  - Telangana (Records: 4,638)\n",
                        "\n",
                        "District: 'Leh'\n",
                        "  - Jammu and Kashmir (Records: 431)\n",
                        "  - Ladakh (Records: 438)\n",
                        "\n",
                        "District: 'Mahabubnagar'\n",
                        "  - Telangana (Records: 6,608)\n",
                        "  - Andhra Pradesh (Records: 166)\n",
                        "\n",
                        "District: 'Medak'\n",
                        "  - Andhra Pradesh (Records: 4,114)\n",
                        "  - Telangana (Records: 6,754)\n",
                        "\n",
                        "District: 'Nalgonda'\n",
                        "  - Andhra Pradesh (Records: 4,673)\n",
                        "  - Telangana (Records: 5,252)\n",
                        "\n",
                        "District: 'Nizamabad'\n",
                        "  - Andhra Pradesh (Records: 2,416)\n",
                        "  - Telangana (Records: 4,649)\n",
                        "\n",
                        "District: 'Pratapgarh'\n",
                        "  - Rajasthan (Records: 1,328)\n",
                        "  - Uttar Pradesh (Records: 3,819)\n",
                        "\n",
                        "District: 'Raigarh'\n",
                        "  - Chhattisgarh (Records: 1,575)\n",
                        "  - Maharashtra (Records: 5,512)\n",
                        "\n",
                        "District: 'Rupnagar'\n",
                        "  - Punjab (Records: 1,962)\n",
                        "  - Chandigarh (Records: 31)\n",
                        "\n",
                        "District: 'Viluppuram'\n",
                        "  - Tamil Nadu (Records: 7,714)\n",
                        "  - Puducherry (Records: 8)\n",
                        "\n",
                        "District: 'Warangal'\n",
                        "  - Andhra Pradesh (Records: 5,412)\n",
                        "  - Telangana (Records: 6,058)\n"
                    ]
                }
            ],
            "source": [
                "# Check for districts appearing in multiple states\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"DISTRICTS APPEARING IN MULTIPLE STATES\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "district_state_mapping = df.groupby('district')['state'].unique()\n",
                "multi_state_districts = district_state_mapping[district_state_mapping.apply(len) > 1]\n",
                "\n",
                "if len(multi_state_districts) > 0:\n",
                "    print(f\"\\n⚠️ {len(multi_state_districts)} districts found in multiple states:\")\n",
                "    for district, states in multi_state_districts.items():\n",
                "        print(f\"\\nDistrict: '{district}'\")\n",
                "        for state in states:\n",
                "            count = df[(df['district'] == district) & (df['state'] == state)].shape[0]\n",
                "            print(f\"  - {state} (Records: {count:,})\")\n",
                "else:\n",
                "    print(\"\\n✓ No districts appear in multiple states!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "================================================================================\n",
                        "DISTRICT NAME INCONSISTENCIES\n",
                        "================================================================================\n",
                        "\n",
                        "✓ No case/whitespace inconsistencies found in district names!\n"
                    ]
                }
            ],
            "source": [
                "# Check for case inconsistencies in district names\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"DISTRICT NAME INCONSISTENCIES\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "# Group by state and check for district inconsistencies\n",
                "inconsistent_districts_found = False\n",
                "\n",
                "for state in df['state'].unique():\n",
                "    state_df = df[df['state'] == state]\n",
                "    state_df_normalized = state_df.copy()\n",
                "    state_df_normalized['district_normalized'] = state_df_normalized['district'].str.strip().str.lower()\n",
                "    \n",
                "    district_variations = state_df_normalized.groupby('district_normalized')['district'].unique()\n",
                "    inconsistent = district_variations[district_variations.apply(len) > 1]\n",
                "    \n",
                "    if len(inconsistent) > 0:\n",
                "        if not inconsistent_districts_found:\n",
                "            print(\"\\n⚠️ District names with case/whitespace inconsistencies:\")\n",
                "            inconsistent_districts_found = True\n",
                "        \n",
                "        print(f\"\\nState: {state}\")\n",
                "        for normalized, variations in inconsistent.items():\n",
                "            print(f\"  Normalized: '{normalized}'\")\n",
                "            for var in variations:\n",
                "                count = state_df[state_df['district'] == var].shape[0]\n",
                "                print(f\"    - '{var}' (Records: {count:,})\")\n",
                "\n",
                "if not inconsistent_districts_found:\n",
                "    print(\"\\n✓ No case/whitespace inconsistencies found in district names!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Pincode Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "================================================================================\n",
                        "PINCODE ANALYSIS\n",
                        "================================================================================\n",
                        "\n",
                        "Total Unique Pincodes: 19,814\n",
                        "Expected Pincodes in India: ~19,000+\n",
                        "\n",
                        "Pincode Data Type: int64\n",
                        "\n",
                        "Pincode Statistics:\n",
                        "count    2.307730e+06\n",
                        "mean     5.235432e+05\n",
                        "std      1.973077e+05\n",
                        "min      1.100010e+05\n",
                        "25%      3.931300e+05\n",
                        "50%      5.232130e+05\n",
                        "75%      6.891150e+05\n",
                        "max      8.554560e+05\n",
                        "Name: pincode, dtype: float64\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"PINCODE ANALYSIS\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "# Basic pincode statistics\n",
                "unique_pincodes = df['pincode'].unique()\n",
                "print(f\"\\nTotal Unique Pincodes: {len(unique_pincodes):,}\")\n",
                "print(f\"Expected Pincodes in India: ~19,000+\")\n",
                "\n",
                "# Check data type\n",
                "print(f\"\\nPincode Data Type: {df['pincode'].dtype}\")\n",
                "\n",
                "# Basic statistics\n",
                "print(\"\\nPincode Statistics:\")\n",
                "print(df['pincode'].describe())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "================================================================================\n",
                        "PINCODE VALIDATION\n",
                        "================================================================================\n",
                        "\n",
                        "Pincodes with invalid length (not 6 digits): 0\n",
                        "\n",
                        "Non-numeric pincodes: 0\n",
                        "\n",
                        "Pincode distribution by first digit:\n",
                        "pincode_first_digit\n",
                        "1    163417\n",
                        "2    217712\n",
                        "3    213190\n",
                        "4    313478\n",
                        "5    501279\n",
                        "6    354509\n",
                        "7    395502\n",
                        "8    148643\n",
                        "Name: count, dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "# Check for invalid pincodes\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"PINCODE VALIDATION\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "# Convert to string for validation\n",
                "df['pincode_str'] = df['pincode'].astype(str)\n",
                "\n",
                "# Check pincode length (should be 6 digits)\n",
                "invalid_length = df[df['pincode_str'].str.len() != 6]\n",
                "print(f\"\\nPincodes with invalid length (not 6 digits): {len(invalid_length):,}\")\n",
                "if len(invalid_length) > 0:\n",
                "    print(\"\\n⚠️ Sample of invalid length pincodes:\")\n",
                "    print(invalid_length[['state', 'district', 'pincode']].head(10))\n",
                "\n",
                "# Check for non-numeric pincodes\n",
                "non_numeric = df[~df['pincode_str'].str.isdigit()]\n",
                "print(f\"\\nNon-numeric pincodes: {len(non_numeric):,}\")\n",
                "if len(non_numeric) > 0:\n",
                "    print(\"\\n⚠️ Sample of non-numeric pincodes:\")\n",
                "    print(non_numeric[['state', 'district', 'pincode']].head(10))\n",
                "\n",
                "# Check pincode ranges by first digit (Indian pincodes start from 1-9)\n",
                "df['pincode_first_digit'] = df['pincode_str'].str[0]\n",
                "print(\"\\nPincode distribution by first digit:\")\n",
                "print(df['pincode_first_digit'].value_counts().sort_index())\n",
                "\n",
                "# Check for pincodes starting with 0\n",
                "pincodes_start_zero = df[df['pincode_str'].str.startswith('0')]\n",
                "if len(pincodes_start_zero) > 0:\n",
                "    print(f\"\\n⚠️ Pincodes starting with 0: {len(pincodes_start_zero):,}\")\n",
                "    print(pincodes_start_zero[['state', 'district', 'pincode']].head(10))\n",
                "\n",
                "# Clean up temp columns\n",
                "df.drop(['pincode_str', 'pincode_first_digit'], axis=1, inplace=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "================================================================================\n",
                        "PINCODES APPEARING IN MULTIPLE STATES\n",
                        "================================================================================\n",
                        "\n",
                        "⚠️ 705 pincodes found in multiple states:\n",
                        "\n",
                        "Pincode: 140308\n",
                        "  - Punjab (Districts: Sas Nagar (Mohali), S.A.S Nagar(Mohali), Rupnagar, Records: 159)\n",
                        "  - Chandigarh (Districts: Chandigarh, Records: 2)\n",
                        "\n",
                        "Pincode: 140603\n",
                        "  - Punjab (Districts: Sas Nagar (Mohali), S.A.S Nagar(Mohali), Rupnagar, Patiala, Records: 186)\n",
                        "  - Chandigarh (Districts: Mohali, Records: 9)\n",
                        "\n",
                        "Pincode: 140901\n",
                        "  - Punjab (Districts: Sas Nagar (Mohali), S.A.S Nagar(Mohali), Rupnagar, Records: 171)\n",
                        "  - Chandigarh (Districts: Chandigarh, Records: 20)\n",
                        "\n",
                        "Pincode: 160003\n",
                        "  - Chandigarh (Districts: Chandigarh, Rupnagar, Records: 95)\n",
                        "  - Punjab (Districts: Sas Nagar (Mohali), S.A.S Nagar(Mohali), Records: 12)\n",
                        "\n",
                        "Pincode: 160014\n",
                        "  - Chandigarh (Districts: Chandigarh, Rupnagar, Records: 122)\n",
                        "  - Punjab (Districts: Sas Nagar (Mohali), S.A.S Nagar(Mohali), Rupnagar, Records: 138)\n",
                        "\n",
                        "Pincode: 160055\n",
                        "  - Chandigarh (Districts: Chandigarh, Rupnagar, Records: 104)\n",
                        "  - Punjab (Districts: Sas Nagar (Mohali), S.A.S Nagar(Mohali), Rupnagar, Records: 171)\n",
                        "\n",
                        "Pincode: 160062\n",
                        "  - Punjab (Districts: S.A.S Nagar(Mohali), Sas Nagar (Mohali), Rupnagar, Records: 182)\n",
                        "  - Chandigarh (Districts: Chandigarh, Records: 42)\n",
                        "\n",
                        "Pincode: 160103\n",
                        "  - Chandigarh (Districts: Chandigarh, Records: 90)\n",
                        "  - Punjab (Districts: Sas Nagar (Mohali), S.A.S Nagar(Mohali), Rupnagar, Records: 200)\n",
                        "\n",
                        "Pincode: 194101\n",
                        "  - Jammu and Kashmir (Districts: Leh, Leh (Ladakh), Records: 101)\n",
                        "  - Ladakh (Districts: Leh, Records: 94)\n",
                        "\n",
                        "Pincode: 194102\n",
                        "  - Jammu and Kashmir (Districts: Kargil, Records: 80)\n",
                        "  - Ladakh (Districts: Kargil, Records: 82)\n",
                        "\n",
                        "... and 695 more\n"
                    ]
                }
            ],
            "source": [
                "# Check for pincodes appearing in multiple states\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"PINCODES APPEARING IN MULTIPLE STATES\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "pincode_state_mapping = df.groupby('pincode')['state'].unique()\n",
                "multi_state_pincodes = pincode_state_mapping[pincode_state_mapping.apply(len) > 1]\n",
                "\n",
                "if len(multi_state_pincodes) > 0:\n",
                "    print(f\"\\n⚠️ {len(multi_state_pincodes)} pincodes found in multiple states:\")\n",
                "    # Show first 10\n",
                "    for pincode, states in list(multi_state_pincodes.items())[:10]:\n",
                "        print(f\"\\nPincode: {pincode}\")\n",
                "        for state in states:\n",
                "            count = df[(df['pincode'] == pincode) & (df['state'] == state)].shape[0]\n",
                "            districts = df[(df['pincode'] == pincode) & (df['state'] == state)]['district'].unique()\n",
                "            print(f\"  - {state} (Districts: {', '.join(districts)}, Records: {count:,})\")\n",
                "    \n",
                "    if len(multi_state_pincodes) > 10:\n",
                "        print(f\"\\n... and {len(multi_state_pincodes) - 10} more\")\n",
                "else:\n",
                "    print(\"\\n✓ No pincodes appear in multiple states!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "================================================================================\n",
                        "PINCODES IN MULTIPLE DISTRICTS (SAME STATE)\n",
                        "================================================================================\n",
                        "\n",
                        "⚠️ Pincodes appearing in multiple districts within the same state:\n",
                        "\n",
                        "State: Andaman and Nicobar Islands\n",
                        "  Pincode 744101: Andamans, South Andaman\n",
                        "  Pincode 744102: South Andaman, Andamans\n",
                        "  Pincode 744103: South Andaman, Andamans\n",
                        "  ... and 11 more pincodes\n",
                        "\n",
                        "State: Andhra Pradesh\n",
                        "  Pincode 500005: Hyderabad, Rangareddi, K.V.Rangareddy, K.V. Rangareddy\n",
                        "  Pincode 500008: Hyderabad, Rangareddi, K.V.Rangareddy\n",
                        "  Pincode 500014: Rangareddi, K.V.Rangareddy, Hyderabad, K.V. Rangareddy\n",
                        "  ... and 1000 more pincodes\n",
                        "\n",
                        "State: Arunachal Pradesh\n",
                        "  Pincode 786629: Tirap, Longding\n",
                        "  Pincode 786630: Tirap, Longding\n",
                        "  Pincode 786631: Longding, Tirap\n",
                        "  ... and 14 more pincodes\n",
                        "\n",
                        "State: Assam\n",
                        "  Pincode 781001: Kamrup Metro, Kamrup\n",
                        "  Pincode 781003: Kamrup Metro, Kamrup\n",
                        "  Pincode 781004: Kamrup Metro, Kamrup\n",
                        "  ... and 294 more pincodes\n",
                        "\n",
                        "State: Bihar\n",
                        "  Pincode 801304: Nalanda, Patna\n",
                        "  Pincode 801305: Nalanda, Patna\n",
                        "  Pincode 802112: Bhojpur, Buxar\n",
                        "  ... and 361 more pincodes\n"
                    ]
                }
            ],
            "source": [
                "# Check for pincodes appearing in multiple districts within the same state\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"PINCODES IN MULTIPLE DISTRICTS (SAME STATE)\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "multi_district_pincodes = []\n",
                "\n",
                "for state in df['state'].unique():\n",
                "    state_df = df[df['state'] == state]\n",
                "    pincode_districts = state_df.groupby('pincode')['district'].unique()\n",
                "    multi_districts = pincode_districts[pincode_districts.apply(len) > 1]\n",
                "    \n",
                "    if len(multi_districts) > 0:\n",
                "        multi_district_pincodes.append((state, multi_districts))\n",
                "\n",
                "if multi_district_pincodes:\n",
                "    print(\"\\n⚠️ Pincodes appearing in multiple districts within the same state:\")\n",
                "    for state, pincodes in multi_district_pincodes[:5]:  # Show first 5 states\n",
                "        print(f\"\\nState: {state}\")\n",
                "        for pincode, districts in list(pincodes.items())[:3]:  # Show first 3 pincodes per state\n",
                "            print(f\"  Pincode {pincode}: {', '.join(districts)}\")\n",
                "        if len(pincodes) > 3:\n",
                "            print(f\"  ... and {len(pincodes) - 3} more pincodes\")\n",
                "else:\n",
                "    print(\"\\n✓ No pincodes appear in multiple districts within the same state!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Data Type Validation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "================================================================================\n",
                        "DATA TYPE VALIDATION\n",
                        "================================================================================\n",
                        "\n",
                        "Numeric Column Data Types:\n",
                        "age_0_5                             : int64\n",
                        "age_5_17                            : int64\n",
                        "age_18_greater                      : int64\n",
                        "bio_age_5_17                        : int64\n",
                        "bio_age_18_greater                  : int64\n",
                        "demo_age_5_17                       : int64\n",
                        "demo_age_18_greater                 : int64\n",
                        "total_enrolments                    : int64\n",
                        "total_biometric_updates             : int64\n",
                        "total_demographic_updates           : int64\n",
                        "total_updates                       : int64\n",
                        "overall_activity                    : int64\n",
                        "update_to_enrolment_ratio           : float64\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"DATA TYPE VALIDATION\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "# Check numeric columns\n",
                "numeric_columns = [\n",
                "    'age_0_5', 'age_5_17', 'age_18_greater',\n",
                "    'bio_age_5_17', 'bio_age_18_greater',\n",
                "    'demo_age_5_17', 'demo_age_18_greater',\n",
                "    'total_enrolments', 'total_biometric_updates', 'total_demographic_updates',\n",
                "    'total_updates', 'overall_activity', 'update_to_enrolment_ratio'\n",
                "]\n",
                "\n",
                "print(\"\\nNumeric Column Data Types:\")\n",
                "for col in numeric_columns:\n",
                "    if col in df.columns:\n",
                "        print(f\"{col:<35} : {df[col].dtype}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "================================================================================\n",
                        "NEGATIVE VALUES CHECK\n",
                        "================================================================================\n",
                        "\n",
                        "✓ No negative values found in numeric columns!\n"
                    ]
                }
            ],
            "source": [
                "# Check for negative values in numeric columns (where they shouldn't exist)\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"NEGATIVE VALUES CHECK\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "negative_issues = False\n",
                "for col in numeric_columns:\n",
                "    if col in df.columns:\n",
                "        if pd.api.types.is_numeric_dtype(df[col]):\n",
                "            negative_count = (df[col] < 0).sum()\n",
                "            if negative_count > 0:\n",
                "                print(f\"\\n⚠️ Column '{col}' has {negative_count:,} negative values\")\n",
                "                negative_issues = True\n",
                "\n",
                "if not negative_issues:\n",
                "    print(\"\\n✓ No negative values found in numeric columns!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "================================================================================\n",
                        "DATE COLUMN VALIDATION\n",
                        "================================================================================\n",
                        "\n",
                        "Date column data type: object\n",
                        "✓ Date column can be parsed as datetime\n",
                        "\n",
                        "Date range: 2025-03-01 00:00:00 to 2025-12-31 00:00:00\n",
                        "Total unique dates: 115\n"
                    ]
                }
            ],
            "source": [
                "# Check date column\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"DATE COLUMN VALIDATION\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "print(f\"\\nDate column data type: {df['date'].dtype}\")\n",
                "\n",
                "# Try to parse dates\n",
                "try:\n",
                "    df['date_parsed'] = pd.to_datetime(df['date'])\n",
                "    print(\"✓ Date column can be parsed as datetime\")\n",
                "    print(f\"\\nDate range: {df['date_parsed'].min()} to {df['date_parsed'].max()}\")\n",
                "    print(f\"Total unique dates: {df['date_parsed'].nunique():,}\")\n",
                "    df.drop('date_parsed', axis=1, inplace=True)\n",
                "except Exception as e:\n",
                "    print(f\"\\n⚠️ Error parsing date column: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Additional Data Quality Checks"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "================================================================================\n",
                        "WHITESPACE ISSUES CHECK\n",
                        "================================================================================\n",
                        "\n",
                        "✓ No whitespace issues found in string columns!\n"
                    ]
                }
            ],
            "source": [
                "# Check for whitespace issues in string columns\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"WHITESPACE ISSUES CHECK\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "string_columns = ['state', 'district', 'month_name', 'day_name']\n",
                "whitespace_issues = False\n",
                "\n",
                "for col in string_columns:\n",
                "    if col in df.columns:\n",
                "        # Check for leading/trailing whitespace\n",
                "        leading_space = df[df[col].str.startswith(' ')].shape[0]\n",
                "        trailing_space = df[df[col].str.endswith(' ')].shape[0]\n",
                "        \n",
                "        if leading_space > 0 or trailing_space > 0:\n",
                "            print(f\"\\n⚠️ Column '{col}':\")\n",
                "            if leading_space > 0:\n",
                "                print(f\"  - Leading whitespace: {leading_space:,} rows\")\n",
                "            if trailing_space > 0:\n",
                "                print(f\"  - Trailing whitespace: {trailing_space:,} rows\")\n",
                "            whitespace_issues = True\n",
                "\n",
                "if not whitespace_issues:\n",
                "    print(\"\\n✓ No whitespace issues found in string columns!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "================================================================================\n",
                        "EMPTY STRING CHECK\n",
                        "================================================================================\n",
                        "\n",
                        "✓ No empty strings found in string columns!\n"
                    ]
                }
            ],
            "source": [
                "# Check for empty strings\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"EMPTY STRING CHECK\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "empty_string_issues = False\n",
                "for col in string_columns:\n",
                "    if col in df.columns:\n",
                "        empty_count = (df[col] == '').sum()\n",
                "        if empty_count > 0:\n",
                "            print(f\"\\n⚠️ Column '{col}' has {empty_count:,} empty strings\")\n",
                "            empty_string_issues = True\n",
                "\n",
                "if not empty_string_issues:\n",
                "    print(\"\\n✓ No empty strings found in string columns!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Monthly Data Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "================================================================================\n",
                        "MONTHLY DATA ANALYSIS\n",
                        "================================================================================\n",
                        "\n",
                        "Monthly Distribution:\n",
                        "==============================\n",
                        " year month_name  unique_days  record_count\n",
                        " 2025      March           10         22346\n",
                        " 2025      April            1         21528\n",
                        " 2025        May            1         21919\n",
                        " 2025       June            1         22068\n",
                        " 2025       July            1         22314\n",
                        " 2025  September           30        551365\n",
                        " 2025    October           18        394907\n",
                        " 2025   November           24        566711\n",
                        " 2025   December           29        684572\n",
                        "\n",
                        "⚠️ Missing months between March 2025 and December 2025:\n",
                        "August\n",
                        "\n",
                        "Observations:\n",
                        "  - March 2025 has only 10 days of data.\n",
                        "  - April 2025 has only 1 days of data.\n",
                        "  - May 2025 has only 1 days of data.\n",
                        "  - June 2025 has only 1 days of data.\n",
                        "  - July 2025 has only 1 days of data.\n",
                        "  - October 2025 has only 18 days of data.\n",
                        "  - November 2025 has only 24 days of data.\n"
                    ]
                }
            ],
            "source": [
                "# Check records per month\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"MONTHLY DATA ANALYSIS\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "# Ensure date is datetime for accurate sorting\n",
                "df['date_dt'] = pd.to_datetime(df['date'])\n",
                "df['month_num'] = df['date_dt'].dt.month\n",
                "df['year'] = df['date_dt'].dt.year\n",
                "\n",
                "# Records per month\n",
                "monthly_stats = df.groupby(['year', 'month_num', 'month_name']).agg({\n",
                "    'date': 'nunique',\n",
                "    'state': 'count'\n",
                "}).rename(columns={'date': 'unique_days', 'state': 'record_count'}).reset_index()\n",
                "\n",
                "monthly_stats = monthly_stats.sort_values(['year', 'month_num'])\n",
                "\n",
                "print(\"\\nMonthly Distribution:\")\n",
                "print(\"=\"*30)\n",
                "print(monthly_stats[['year', 'month_name', 'unique_days', 'record_count']].to_string(index=False))\n",
                "\n",
                "# Check for missing months in the range\n",
                "all_months_range = pd.date_range(start=df['date_dt'].min(), end=df['date_dt'].max(), freq='MS').strftime('%B').tolist()\n",
                "present_months = df['month_name'].unique().tolist()\n",
                "missing_months = [m for m in all_months_range if m not in present_months]\n",
                "\n",
                "if missing_months:\n",
                "    print(f\"\\n⚠️ Missing months between {df['date_dt'].min().strftime('%B %Y')} and {df['date_dt'].max().strftime('%B %Y')}:\")\n",
                "    print(\", \".join(missing_months))\n",
                "else:\n",
                "    print(f\"\\n✓ All months between {df['date_dt'].min().strftime('%B %Y')} and {df['date_dt'].max().strftime('%B %Y')} are present!\")\n",
                "\n",
                "# Check for consistency in days per month\n",
                "print(\"\\nObservations:\")\n",
                "for _, row in monthly_stats.iterrows():\n",
                "    if row['unique_days'] < 28:\n",
                "        print(f\"  - {row['month_name']} {row['year']} has only {row['unique_days']} days of data.\")\n",
                "\n",
                "# Clean up temp columns\n",
                "df.drop(['date_dt', 'month_num', 'year'], axis=1, inplace=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 11. Summary Report"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "================================================================================\n",
                        "SUMMARY REPORT\n",
                        "================================================================================\n",
                        "\n",
                        "Dataset Overview:\n",
                        "  - Total Rows: 2,307,730\n",
                        "  - Total Columns: 20\n",
                        "  - Memory Usage: 899.92 MB\n",
                        "\n",
                        "Data Quality Metrics:\n",
                        "  - Total Null Values: 0\n",
                        "  - Duplicate Rows: 0\n",
                        "  - Unique States: 36\n",
                        "  - Unique Districts: 1001\n",
                        "  - Unique Pincodes: 19,814\n",
                        "  - Unique Dates: 115\n",
                        "\n",
                        "Data Ranges:\n",
                        "  - Total Enrolments: 0 to 3,965\n",
                        "  - Total Updates: 0 to 28,298\n",
                        "  - Overall Activity: 0 to 30,000\n",
                        "\n",
                        "================================================================================\n",
                        "DATA QUALITY CHECK COMPLETED!\n",
                        "================================================================================\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"SUMMARY REPORT\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "print(f\"\\nDataset Overview:\")\n",
                "print(f\"  - Total Rows: {df.shape[0]:,}\")\n",
                "print(f\"  - Total Columns: {df.shape[1]}\")\n",
                "print(f\"  - Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
                "\n",
                "print(f\"\\nData Quality Metrics:\")\n",
                "print(f\"  - Total Null Values: {df.isnull().sum().sum():,}\")\n",
                "print(f\"  - Duplicate Rows: {df.duplicated().sum():,}\")\n",
                "print(f\"  - Unique States: {df['state'].nunique()}\")\n",
                "print(f\"  - Unique Districts: {df['district'].nunique()}\")\n",
                "print(f\"  - Unique Pincodes: {df['pincode'].nunique():,}\")\n",
                "print(f\"  - Unique Dates: {df['date'].nunique():,}\")\n",
                "\n",
                "print(f\"\\nData Ranges:\")\n",
                "print(f\"  - Total Enrolments: {df['total_enrolments'].min():,.0f} to {df['total_enrolments'].max():,.0f}\")\n",
                "print(f\"  - Total Updates: {df['total_updates'].min():,.0f} to {df['total_updates'].max():,.0f}\")\n",
                "print(f\"  - Overall Activity: {df['overall_activity'].min():,.0f} to {df['overall_activity'].max():,.0f}\")\n",
                "\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"DATA QUALITY CHECK COMPLETED!\")\n",
                "print(\"=\"*80)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.14.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
